ğŸ“š Chat with Multiple PDFs

An AI-powered RAG (Retrieval-Augmented Generation) application that lets you upload multiple PDF documents and ask questions about their content using natural language.

The app retrieves relevant document chunks and generates accurate answers using a fast LLM.

âœ¨ Features

ğŸ“„ Upload multiple PDF files

ğŸ¤– Ask questions in natural language

ğŸ” Answers grounded only in uploaded documents

ğŸ“Œ View source document chunks for transparency

âš¡ Fast responses powered by Groq

ğŸ§  How It Works (High Level)

PDFs are uploaded and parsed

Text is split into chunks

Chunks are embedded using Sentence Transformers

Embeddings are stored in ChromaDB

Relevant chunks are retrieved for each query

Groq LLM generates answers using retrieved context

ğŸ›  Tech Stack

Streamlit â€“ Web UI

LangChain â€“ RAG orchestration

Groq â€“ Fast LLM inference

ChromaDB â€“ Vector database (cloud-safe)

Sentence Transformers â€“ Text embeddings

PyPDF â€“ PDF parsing

âš ï¸ FAISS was intentionally removed to ensure Streamlit Cloud compatibility.

ğŸš€ Local Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/aswinalakkad/Chat_with_multiple_PDFs.git
cd Chat_with_multiple_PDFs

2ï¸âƒ£ Create & activate environment (recommended)
conda create -n chatpdf python=3.10 -y
conda activate chatpdf

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Groq API Key

Create .streamlit/secrets.toml:

GROQ_API_KEY = "your_groq_api_key_here"


OR set it as an environment variable:

export GROQ_API_KEY="your_groq_api_key_here"

5ï¸âƒ£ Run the app
streamlit run app.py

â˜ï¸ Deployment

This application is deployed using Streamlit Community Cloud and is fully compatible with CPU-only environments.

ğŸ“Œ Notes

Answers are generated only from document context

If the answer is not found, the model clearly states so

No hallucinated or external information is used

ğŸ“„ License

MIT License
